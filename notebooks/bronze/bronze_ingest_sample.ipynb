{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab66433a-6de4-442d-85be-da0be1fd52a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS workspace.bronze;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a99a5e-ae0d-4b09-9561-33f750674c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE workspace.bronze;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9eeb6ba-dce6-4959-9e84-5e4fd776f922",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DEV version - ready for promotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f78a73-e6ff-407a-90db-4272b9cdb102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col, lit\n",
    "\n",
    "# 1. Read raw files\n",
    "raw_df = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .csv(\"/databricks-datasets/samples/population-vs-price\")\n",
    "         .withColumn(\"file_path\", col(\"_metadata.file_path\"))\n",
    ")\n",
    "\n",
    "# 2. Read metadata table\n",
    "audit_df = spark.read.table(\"workspace.metadata.file_ingestion_audit\")\n",
    "\n",
    "# 3. Collect already processed files (small control table)\n",
    "processed_files = (\n",
    "    audit_df\n",
    "    .filter(col(\"status\") == \"SUCCESS\")\n",
    "    .select(\"file_path\")\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "# 4. Filter new files (NO JOIN USING)\n",
    "new_files_df = raw_df.filter(\n",
    "    ~col(\"file_path\").isin([row.file_path for row in processed_files.collect()])\n",
    ")\n",
    "display(new_files_df)\n",
    "\n",
    "# 5. Bronze transformation\n",
    "bronze_df = (\n",
    "    new_files_df\n",
    "    .withColumnRenamed(\"2014 rank\", \"rank_2014\")\n",
    "    .withColumnRenamed(\"State Code\", \"state_code\")\n",
    "    .withColumnRenamed(\"2014 Population estimate\", \"population_estimate_2014\")\n",
    "    .withColumnRenamed(\"2015 median sales price\", \"median_sales_price_2015\")\n",
    "    .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    ")\n",
    "\n",
    "# 6. Write Bronze incrementally\n",
    "bronze_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"workspace.bronze.population_raw\")\n",
    "\n",
    "# 7. Update metadata table\n",
    "files_ingested_df = (\n",
    "    bronze_df\n",
    "    .select(col(\"file_path\"))\n",
    "    .distinct()\n",
    "    .withColumn(\"ingestion_time\", current_timestamp())\n",
    "    .withColumn(\"status\", lit(\"SUCCESS\"))\n",
    ")\n",
    "\n",
    "bronze_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"workspace.bronze.population_raw\")\n",
    "\n",
    "\n",
    "display(bronze_df)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6578620526840764,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingest_sample",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
